{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>cleaning_fee_True</th>\n",
       "      <th>host_has_profile_pic_t</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "      <th>property_type_encoded</th>\n",
       "      <th>room_type_encoded</th>\n",
       "      <th>bed_type_encoded</th>\n",
       "      <th>cancellation_policy_encoded</th>\n",
       "      <th>city_encoded</th>\n",
       "      <th>des_sentiment_analysis</th>\n",
       "      <th>name_sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>-0.072621</td>\n",
       "      <td>-0.404046</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>-0.312048</td>\n",
       "      <td>-0.566461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221989</td>\n",
       "      <td>0.879947</td>\n",
       "      <td>0.206922</td>\n",
       "      <td>1.031946</td>\n",
       "      <td>-0.417068</td>\n",
       "      <td>0.216242</td>\n",
       "      <td>-0.435248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>1.783653</td>\n",
       "      <td>-0.404046</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>2.034955</td>\n",
       "      <td>1.027816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.248121</td>\n",
       "      <td>0.883912</td>\n",
       "      <td>0.178912</td>\n",
       "      <td>1.034251</td>\n",
       "      <td>-0.425829</td>\n",
       "      <td>0.837002</td>\n",
       "      <td>-1.788095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>0.855516</td>\n",
       "      <td>-0.404046</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>-0.312048</td>\n",
       "      <td>1.027816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.252342</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.126796</td>\n",
       "      <td>-0.607644</td>\n",
       "      <td>-0.445747</td>\n",
       "      <td>0.808508</td>\n",
       "      <td>-0.133695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.620073</td>\n",
       "      <td>0.391448</td>\n",
       "      <td>-0.404046</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>0.861454</td>\n",
       "      <td>0.230678</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187295</td>\n",
       "      <td>0.883912</td>\n",
       "      <td>0.178912</td>\n",
       "      <td>-0.976832</td>\n",
       "      <td>2.696289</td>\n",
       "      <td>0.213627</td>\n",
       "      <td>-0.926212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>-0.536689</td>\n",
       "      <td>-0.404046</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>-1.485549</td>\n",
       "      <td>-0.566461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.242856</td>\n",
       "      <td>0.875005</td>\n",
       "      <td>0.145414</td>\n",
       "      <td>-0.634193</td>\n",
       "      <td>1.380088</td>\n",
       "      <td>-0.101872</td>\n",
       "      <td>-0.095776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_price  accommodates  bathrooms  host_response_rate  bedrooms      beds  \\\n",
       "0   5.010635     -0.072621  -0.404046            0.296013 -0.312048 -0.566461   \n",
       "1   5.129899      1.783653  -0.404046            0.296013  2.034955  1.027816   \n",
       "2   4.976734      0.855516  -0.404046            0.296013 -0.312048  1.027816   \n",
       "3   6.620073      0.391448  -0.404046            0.296013  0.861454  0.230678   \n",
       "4   4.744932     -0.536689  -0.404046            0.296013 -1.485549 -0.566461   \n",
       "\n",
       "   cleaning_fee_True  host_has_profile_pic_t  host_identity_verified_t  \\\n",
       "0                  1                       1                         1   \n",
       "1                  1                       1                         0   \n",
       "2                  1                       1                         1   \n",
       "3                  1                       1                         1   \n",
       "4                  1                       1                         1   \n",
       "\n",
       "   instant_bookable_t  property_type_encoded  room_type_encoded  \\\n",
       "0                   0              -0.221989           0.879947   \n",
       "1                   1              -0.248121           0.883912   \n",
       "2                   1              -0.252342           0.869698   \n",
       "3                   0               0.187295           0.883912   \n",
       "4                   1              -0.242856           0.875005   \n",
       "\n",
       "   bed_type_encoded  cancellation_policy_encoded  city_encoded  \\\n",
       "0          0.206922                     1.031946     -0.417068   \n",
       "1          0.178912                     1.034251     -0.425829   \n",
       "2          0.126796                    -0.607644     -0.445747   \n",
       "3          0.178912                    -0.976832      2.696289   \n",
       "4          0.145414                    -0.634193      1.380088   \n",
       "\n",
       "   des_sentiment_analysis  name_sentiment_analysis  \n",
       "0                0.216242                -0.435248  \n",
       "1                0.837002                -1.788095  \n",
       "2                0.808508                -0.133695  \n",
       "3                0.213627                -0.926212  \n",
       "4               -0.101872                -0.095776  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = './airbnb_dataset/milestone3.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df.columns if col != 'log_price' and df[col].dtype in ['int64', 'float64']]\n",
    "X = df[features]\n",
    "y = df['log_price']\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment if first time run\n",
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dval = xgb.DMatrix(X_val, label=y_val)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# #hyperparam may need here\n",
    "# param = {\n",
    "#     'max_depth': 6,\n",
    "#     'eta': 0.1,\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eval_metric': 'rmse'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.6, 'eta': 0.05, 'max_depth': 7, 'subsample': 0.8}\n",
      "Train MSE:  0.1490166415744588\n",
      "Test MSE:  0.17929578089980588\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a wide range of hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'eta': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Create an XGBoost regressor object\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=250, random_state=42,objective='reg:squarederror', eval_metric='rmse',early_stopping_rounds=10)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=False, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_full, y_train_full, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Train MSE: \", mse_train)\n",
    "print(\"Test MSE: \", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_round = 150\n",
    "# evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "# model = xgb.train(param, dtrain, num_round, evals=evals, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.397022\n",
      "Train MSE: 0.157627\n",
      "Test RMSE: 0.425769\n",
      "Test MSE: 0.181279\n"
     ]
    }
   ],
   "source": [
    "# # model = xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "# # Training error\n",
    "# y_pred_train = model.predict(dtrain)\n",
    "# mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "# rmse_train = np.sqrt(mse_train)\n",
    "# print(\"Train RMSE: %f\" % rmse_train)\n",
    "# print(\"Train MSE: %f\" % mse_train)\n",
    "\n",
    "# # Test error\n",
    "# y_pred_test = model.predict(dtest)\n",
    "# mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "# rmse_test = np.sqrt(mse_test)\n",
    "# print(\"Test RMSE: %f\" % rmse_test)\n",
    "# print(\"Test MSE: %f\" % mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 44352, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 4.784914\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l2: 0.179938\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Prepare datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',  # or 'regression' for regression\n",
    "    'metric': 'l2',  # or 'l2' for regression\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05\n",
    "}\n",
    "\n",
    "# Train model\n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[valid_data], callbacks=[lgb.early_stopping(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.428728\n",
      "Test MSE: 0.183807\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "# Test error\n",
    "y_pred_test = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "print(\"Test RMSE: %f\" % rmse_test)\n",
    "print(\"Test MSE: %f\" % mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model K-Fold Cross-Validation\n",
    "\n",
    "We performed K-fold cross-validation on our dataset using the XGBoost algorithm to predict Airbnb listing prices. This approach helps us to understand how well our model generalizes on unseen data by dividing the dataset into `k` distinct subsets (or folds), then iteratively training the model on `k-1` subsets while using the remaining subset for validation. The process is repeated `k` times, with each subset serving as the validation set exactly once.\n",
    "\n",
    "#### Cross-Validation Parameters\n",
    "- **Objective**: Regression with squared error.\n",
    "- **Max Depth**: 5 layers to control the complexity of the model.\n",
    "- **Eta (Learning Rate)**: 0.3 to control the model's learning rate.\n",
    "- **Evaluation Metric**: Root Mean Squared Error (RMSE), a standard metric for regression tasks.\n",
    "\n",
    "#### Results\n",
    "After performing 5-fold cross-validation, the model demonstrated the following results:\n",
    "- **Mean RMSE**: 0.42461, indicating the average error across all folds.\n",
    "- **Standard Deviation of RMSE**: 0.00387, showing the variability in the RMSE across folds. This low standard deviation suggests that the model's performance is relatively consistent across different subsets of the data.\n",
    "\n",
    "The detailed training process showed a steady decrease in RMSE from the initial rounds to the final iteration.The XGBoost model's performance, as evidenced by K-fold cross-validation, suggests it is a reliable and consistent approach for predicting Airbnb listing prices. The relatively low and stable RMSE across folds signifies good model generalization. Further optimization and testing may refine the model, potentially leading to even more accurate predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
